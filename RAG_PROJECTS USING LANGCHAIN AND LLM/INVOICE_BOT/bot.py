import streamlit as st
import ollama
import os
import shutil
import hashlib
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS

# Setup
model = 'mistral'
client = ollama.Client()

data_path = 'C:/Users/tbaka/OneDrive/Desktop/RAG_PROJECTS/INVOICE_BOT/Data/'
os.makedirs(data_path, exist_ok=True)

db_faiss_path = 'Faiss/'
os.makedirs(db_faiss_path, exist_ok=True)

# Utility: Generate hash for a file (used to identify unique uploads)
def get_file_hash(file_path):
    with open(file_path, "rb") as f:
        return hashlib.md5(f.read()).hexdigest()

# Load and split document
def load_data(data_path):
    ext = data_path.split('.')[-1].lower()
    if ext == 'pdf':
        loader = PyPDFLoader(data_path)
    else:
        raise ValueError(f"Unsupported file format: {ext}")
    return loader.load_and_split()

# Split into chunks
def create_chunks(extracted_data):
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500, 
        chunk_overlap=50,
        length_function=len
    )
    text_chunks = text_splitter.split_documents(extracted_data)
    return text_chunks

# Embed and store in FAISS
def create_embeddings(text_chunks):
    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')
    vectorstore = FAISS.from_documents(text_chunks, embedding=embeddings)
    return vectorstore

# Load existing FAISS vector DB
def load_vector_store(vector_dir):
    embedding_model = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')
    db = FAISS.load_local(vector_dir, embeddings=embedding_model, allow_dangerous_deserialization=True)
    return db

# --- Streamlit UI ---
st.title('Invoice Bot')
st.markdown("RAG tool to retrieve relevant information based on your query")
st.header('Upload Invoice Receipt')

uploaded_file = st.file_uploader("Choose a PDF file", type=["pdf", "txt", "docx", "csv"])

if uploaded_file is not None:
    # Save uploaded file to disk
    file_path = os.path.join(data_path, uploaded_file.name)
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())

    st.success(f"File '{uploaded_file.name}' uploaded successfully!")
    st.info("‚úÖ Processing the file...")

    # Generate unique hash and create vector DB folder for this file
    file_hash = get_file_hash(file_path)
    vector_dir = os.path.join(db_faiss_path, file_hash)
    os.makedirs(vector_dir, exist_ok=True)

    if not os.listdir(vector_dir):  # If DB for this file doesn't exist
        try:
            documents = load_data(data_path=file_path)
            st.success('‚úÖ Loading the documents')
            text_chunks = create_chunks(extracted_data=documents)
            st.success("‚úÖ Creating the text chunks")
            vectorstore = create_embeddings(text_chunks=text_chunks)
            st.success("‚úÖ Creating the vector database")
            vectorstore.save_local(vector_dir)
            st.success(f"‚úÖ Vector Database saved successfully at {vector_dir}!")   
        except Exception as e:
            st.error(f"‚ùå Error processing the file: {e}")
    else:
        st.info("‚ÑπÔ∏è Vector database already exists for this file. Skipping creation.")

    # Store the vector path for retrieval
    st.session_state["vector_path"] = vector_dir

# Query input
user_query = st.text_input('Enter your query : ', placeholder='e.g,. What is the total amount in invoice #123?')

# Action button
if st.button('üîç Retrieve Context'):
    if user_query.strip() == "":
        st.warning("‚ö†Ô∏è Please enter a query.")
    elif "vector_path" not in st.session_state:
        st.warning("‚ö†Ô∏è Upload a document before querying.")
    else:
        try:
            st.info("üîé Searching from Vector Database...")    
            db = load_vector_store(st.session_state["vector_path"])
            doc = db.similarity_search(user_query, k=1)
            prompt_template = """Hi, your name is Hr_bot generated by Tushar khitoliya : Give me the {query} from HR poclicy in {similar_query}. No irrelevant info. 
            Provide me the exact information in words only. or higlight the relevant information 
            Please provide the answer in a Bulletin Point by focusing on the main topics to cover! 
            after proving the information you can ask me for the next query ?."""
            prompt = prompt_template.format(query=user_query, similar_query=doc)
            output = client.generate(model=model, prompt=prompt).response

            if output:
                st.success("‚úÖ Documents retrieved successfully!")
                st.subheader("üìÑ Retrieved Answer:")
                st.write(output)
            else:
                st.error("‚ùå No relevant documents found for your query.") 
        except Exception as e:
            st.error(f"‚ùå Failed to retrieve information: {str(e)}")

# Stop button to clean up
if st.button("üõë Stop it's processing"):
    try:
        if os.path.exists(db_faiss_path):
            shutil.rmtree(db_faiss_path)
        if os.path.exists(data_path):
            shutil.rmtree(data_path)
        st.success("‚úÖ All data deleted successfully.")
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Could not delete folders: {e}")
    os._exit(0)
