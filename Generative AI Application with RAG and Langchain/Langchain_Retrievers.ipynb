{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e3d7ff3-dfbb-4018-ab57-d810e20cc434",
   "metadata": {},
   "source": [
    "# load the data from website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "df71014c-257c-447a-bd78-c53c7035f008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/i5V3ACEyz6hnYpVq6MTSvg/state-of-the-union.txt\")\n",
    "\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c2a93b55-7a9a-4959-9a79-f6124807227c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].page_content[:100]\n",
    "text = data[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "aaa4ed28-8ac4-4999-962d-bc841b0c8514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200, chunk_overlap=30,\n",
    "    length_function=len )\n",
    "\n",
    "text_chunks = splitter.split_text(text)\n",
    "text_chunks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b038ce-a122-4f53-8c41-ee85b282d677",
   "metadata": {},
   "source": [
    "# Lets Use PreTrained_Embedding model by HuggingFace library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "59bb8606-2565-442a-bc39-1d0eab46954b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-mpnet-base-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "model_name = 'sentence-transformers/all-mpnet-base-v2'\n",
    "embedding_model = HuggingFaceEmbeddings(model_name = model_name)\n",
    "embedding_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e121c064-5aa6-4cff-ba6b-f40d9fcc7050",
   "metadata": {},
   "source": [
    "# Now lets Create the embeddings for each chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2caa93cd-eeff-4510-a833-fe1d65846228",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_embeddings = embedding_model.embed_documents(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3c14e970-66fa-4ad4-9508-f0b95d0a9cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "271"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunk_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338fb65c-178e-421f-ba36-3cae4ce3c2e9",
   "metadata": {},
   "source": [
    "# Now store these chunks_embeddings into Vectordatabase using ChromaDB and FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6919162e-3e5a-4f23-834d-79bd43fc762e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "271"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = []\n",
    "for i in range(len(text_chunks)):\n",
    "    idx.append(str(i))\n",
    "len(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "89b89cb4-4cbc-4a7f-9d17-0dcc30356048",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "chroma_db = Chroma.from_texts(text_chunks, embedding_model, ids = idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4e8c1c3e-23db-4646-8c0d-8e9dc706ff38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['With a duty to one another to the American people to the Constitution. \\n\\nAnd with an unwavering resolve that freedom will always triumph over tyranny.']\n"
     ]
    }
   ],
   "source": [
    "# print some text_chunks from database\n",
    "print(chroma_db._collection.get('2')['documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c308abbd-03e2-48af-9bb5-9c61c7087fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "271"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the length of database\n",
    "chroma_db._collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8b427138-96cd-4b3c-90c1-c1674aab072d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'child care, to be able to get back to work.'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what is your company policies\"\n",
    "similar_query = chroma_db.similarity_search(query, k=2)\n",
    "similar_query[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ed7049c5-803a-4eb1-b19e-df8aaaff5f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [], 'embeddings': None, 'documents': [], 'uris': None, 'included': ['metadatas', 'documents'], 'data': None, 'metadatas': []}\n"
     ]
    }
   ],
   "source": [
    "# Add data to existing database\n",
    "Q1 = \"we want to add some data into chrome database\"\n",
    "from langchain_core.documents import Document\n",
    "new_chunk = Document(\n",
    "    page_content = Q1,\n",
    "    metadata = {\n",
    "        'source':'ibm.com',\n",
    "        'page' : 1\n",
    "    }\n",
    ")\n",
    "new_chunk = [new_chunk]\n",
    "print(chroma_db._collection.get('542'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "902dd3a9-25b3-411f-98f4-22efeecc60bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['542']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chroma_db.add_documents(\n",
    "    documents = new_chunk,\n",
    "    ids = ['542']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cce897c5-ed85-499b-b656-b84a4bdd4b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': ['542'], 'embeddings': None, 'documents': ['we want to add some data into chrome database'], 'uris': None, 'included': ['metadatas', 'documents'], 'data': None, 'metadatas': [{'page': 1, 'source': 'ibm.com'}]}\n"
     ]
    }
   ],
   "source": [
    "print(chroma_db._collection.get('542'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "20cf68aa-17c1-4ce4-a501-8f3a2271f22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_chunk = Document(\n",
    "    page_content = 'We just updated the 542th index content here',\n",
    "    metadata={\n",
    "        'source':'ibm.com',\n",
    "        'page':1\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e9fd9f1c-beb6-4c69-ab64-c5d5bfeff6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_db.update_document(\n",
    "    '542',\n",
    "    update_chunk\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d628e62d-e629-4169-8a28-0ec8a2add0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [], 'embeddings': None, 'documents': [], 'uris': None, 'included': ['metadatas', 'documents'], 'data': None, 'metadatas': []}\n"
     ]
    }
   ],
   "source": [
    "print(chroma_db._collection.get('542'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "dea6d182-bd6e-46d1-992a-e582938cbce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to delete any document or chunk(text)\n",
    "chroma_db._collection.delete('542')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "17ffe9e5-72a7-489f-98ba-3ab7324791f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [], 'embeddings': None, 'documents': [], 'uris': None, 'included': ['metadatas', 'documents'], 'data': None, 'metadatas': []}\n"
     ]
    }
   ],
   "source": [
    "print(chroma_db._collection.get('542'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780b3c68-9a48-4c59-ba17-db2792be33eb",
   "metadata": {},
   "source": [
    "# Now use a different DataBase like FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f4a969e2-885f-41ac-abbc-fdfdbf9c56f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "faiss_db = FAISS.from_texts(text_chunks, embedding_model, ids = idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "022e795a-696c-4153-a0df-76029d7dc379",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print some stored data from FAISS_DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a618657d-3667-4e1c-a0dc-8d92c63f21cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='child care, to be able to get back to work.'),\n",
       " Document(page_content='Tonight, I’m announcing a crackdown on these companies overcharging American businesses and consumers.')]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what is your company policies\"\n",
    "faiss_db.similarity_search(query, k= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "920b70ae-c08c-462c-9127-1522f1d02c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# faiss_db?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1e357436-b8a4-4d88-8660-193d434ec6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='child care, to be able to get back to work.'),\n",
       " Document(page_content='Tonight, I’m announcing a crackdown on these companies overcharging American businesses and consumers.')]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faiss_db.similarity_search(query, k=2) # simple search the closest content from data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8feb9fe5-a61f-4be8-b508-946f6ce74bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='child care, to be able to get back to work.'),\n",
       " Document(page_content='Tonight, I’m announcing a crackdown on these companies overcharging American businesses and consumers.')]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_query = embedding_model.embed_query(query)\n",
    "faiss_db.similarity_search_by_vector(embedded_query, k =2)   # it will use only embedded_vector of your query then search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e63d9ad4-4c00-4288-837d-2462fd29edf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='child care, to be able to get back to work.'),\n",
       "  1.3609143),\n",
       " (Document(page_content='Tonight, I’m announcing a crackdown on these companies overcharging American businesses and consumers.'),\n",
       "  1.3922057)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faiss_db.similarity_search_with_score(query, k =2)   # search the content and score too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b70cb2b5-4087-48dd-93a7-da6e20afe7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "271"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now count the total vector stored in database\n",
    "faiss_db.index.ntotal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b878a7-4ee1-494a-b781-dc649268f622",
   "metadata": {},
   "source": [
    "# Add data into FAISS_DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "79952898-f612-4776-aad5-486985344a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['35fbcbea-468f-4f8e-aa26-c8303ff02468']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faiss_db.add_texts([\"new doc\"], metadatas=[{\"id\": \"new\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b2f9fb46-e845-4400-973b-9da770a023ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faiss_db.index.ntotal   # after adding one text it becomes 272"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "785015fb-8bb7-4003-b815-70e9bbd6393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your database in directory\n",
    "faiss_db.save_local(\"FAISS_DB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "abd3f95e-08a3-45bf-beb6-105f60dd4c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load your database for embedding new query for Gen_AI applications\n",
    "faiss_db = faiss_db.load_local(\"FAISS_DB\", embedding_model, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "126214e3-e90f-4b66-9723-cd50c7a4deb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x1a4fa620dd0>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faiss_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "deed732b-2e06-4fbb-a9d5-d1026dc052d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='And on testing, we have made hundreds of millions of tests available for you to order for free.'),\n",
       " Document(page_content='But cancer from prolonged exposure to burn pits ravaged Heath’s lungs and body. \\n\\nDanielle says Heath was a fighter to the very end. \\n\\nHe didn’t know how to stop fighting, and neither did she.'),\n",
       " Document(page_content='Intel’s CEO, Pat Gelsinger, who is here tonight, told me they are ready to increase their investment from  \\n$20 billion to $100 billion.'),\n",
       " Document(page_content='We’ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.')]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = faiss_db.as_retriever(search_type = 'mmr')  # Maximum Marginal Relevance Retrieval\n",
    "docs = retriever.invoke(Q1)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "49f48f11-f29c-4179-aae6-1de43e5817c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='And I’m taking robust action to make sure the pain of our sanctions  is targeted at Russia’s economy. And I will use every tool at our disposal to protect American businesses and consumers.'),\n",
       " Document(page_content='It’s time to strengthen privacy protections, ban targeted advertising to children, demand tech companies stop collecting personal data on our children.'),\n",
       " Document(page_content='We got more than 130 countries to agree on a global minimum tax rate so companies can’t get out of paying their taxes at home by shipping jobs and factories overseas.'),\n",
       " Document(page_content='And I ask Congress to pass proven measures to reduce gun violence. Pass universal background checks. Why should anyone on a terrorist list be able to purchase a weapon?')]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faiss_db.as_retriever(search_type = 'mmr').invoke(\"email policy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "55ceb4c0-e7ae-419f-a133-9ac799c18463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='And I’m taking robust action to make sure the pain of our sanctions  is targeted at Russia’s economy. And I will use every tool at our disposal to protect American businesses and consumers.'),\n",
       " Document(page_content='It’s time to strengthen privacy protections, ban targeted advertising to children, demand tech companies stop collecting personal data on our children.'),\n",
       " Document(page_content='As I have made crystal clear the United States and our Allies will defend every inch of territory of NATO countries with the full force of our collective power.'),\n",
       " Document(page_content='And I will keep doing everything in my power to crack down on gun trafficking and ghost guns you can buy online and make at home—they have no serial numbers and can’t be traced.')]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faiss_db.similarity_search(\"email policy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8cf6095c-4bea-4903-bde7-2b9de6a75293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we can see that MMR is more effective and efficient than normal similar_search for searching the most similar or relevant content for the same query "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bfbf1f-6e36-4d49-bbba-d7b0098001ad",
   "metadata": {},
   "source": [
    "# Lets integrate Ollama LLM into the System for Advanced Retriever Processes by langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1cb74fcc-e3f9-4e5c-90da-df3e3a77871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "# Setup Both llm and retriever for Multi Query Retriever\n",
    "llm = Ollama(model = 'llama3.2')\n",
    "faiss_retriever = faiss_db.as_retriever(search_type = 'similarity', search_kwargs = {'k': 3})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2c1541-7db8-4de9-902c-2193dd2ed6b4",
   "metadata": {},
   "source": [
    "# Now make LANGCHAIN Retrievers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf433c0-f5c1-4fd8-a1b1-ad85699553e0",
   "metadata": {},
   "source": [
    "# Multi Query Retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cee893a7-4f34-4450-8bbc-bbe07166f15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever =  faiss_db.as_retriever(search_kwargs = {'k':2}),\n",
    "    llm = llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "26b95610-68f1-4a00-92fe-95f3a148b526",
   "metadata": {},
   "outputs": [],
   "source": [
    "Query = \"how email policy works in this company for their employees\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4630dd44-b819-444b-94c7-8c7ac0234379",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_results = faiss_retriever.invoke(Query)\n",
    "multiquery_results = multi_query_retriever.invoke(Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a607a471-eaf6-4e03-b6e6-ba7c76ab9d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='I’ve worked on these issues a long time.'),\n",
       " Document(page_content='Second – we must prepare for new variants. Over the past year, we’ve gotten much better at detecting new variants.'),\n",
       " Document(page_content='Tonight, I’m announcing a crackdown on these companies overcharging American businesses and consumers.'),\n",
       " Document(page_content='We’ll build a national network of 500,000 electric vehicle charging stations, begin to replace poisonous lead pipes—so every child—and every American—has clean water to drink at home and at school,'),\n",
       " Document(page_content='Here are four common sense steps as we move forward safely.'),\n",
       " Document(page_content='Third – we can end the shutdown of schools and businesses. We have the tools we need.')]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiquery_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8b8af5dc-72ed-4785-b729-36f783c2ee58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='There’s been a law on the books for almost a century \\nto make sure taxpayers’ dollars support American jobs and businesses. \\n\\nEvery Administration says they’ll do it, but we are actually doing it.'),\n",
       " Document(page_content='We’re doing that here in the federal government. The vast majority of federal workers will once again work in person. \\n\\nOur schools are open. Let’s keep it that way. Our kids need to be in school.'),\n",
       " Document(page_content='–on their economy. The Ruble has lost 30% of its value.')]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1bfc8203-f4d3-4bfa-8d72-b3e5dbe07b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There’s been a law on the books for almost a century \\nto make sure taxpayers’ dollars support American jobs and businesses. \\n\\nEvery Administration says they’ll do it, but we are actually doing it.'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_results[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "04f211d2-9caa-4eb3-a954-137f562d5451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved result would be : 1 ---------------->\n",
      "There’s been a law on the books for almost a century \n",
      "to make sure taxpayers’ dollars support American jobs and businesses. \n",
      "\n",
      "Every Administration says they’ll do it, but we are actually doing it.\n",
      "Retrieved result would be : 2 ---------------->\n",
      "We’re doing that here in the federal government. The vast majority of federal workers will once again work in person. \n",
      "\n",
      "Our schools are open. Let’s keep it that way. Our kids need to be in school.\n",
      "Retrieved result would be : 3 ---------------->\n",
      "–on their economy. The Ruble has lost 30% of its value.\n"
     ]
    }
   ],
   "source": [
    "for i , docs in enumerate(similarity_results):\n",
    "    print(f\"Retrieved result would be : {i+1} ---------------->\")\n",
    "    print(docs.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c2695c64-f3dc-4193-a3a3-913653e65e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved result would be : 1 ---------------->\n",
      "I’ve worked on these issues a long time.\n",
      "--------------------------------------------- >\n",
      "Retrieved result would be : 2 ---------------->\n",
      "Second – we must prepare for new variants. Over the past year, we’ve gotten much better at detecting new variants.\n",
      "--------------------------------------------- >\n",
      "Retrieved result would be : 3 ---------------->\n",
      "Tonight, I’m announcing a crackdown on these companies overcharging American businesses and consumers.\n",
      "--------------------------------------------- >\n",
      "Retrieved result would be : 4 ---------------->\n",
      "We’ll build a national network of 500,000 electric vehicle charging stations, begin to replace poisonous lead pipes—so every child—and every American—has clean water to drink at home and at school,\n",
      "--------------------------------------------- >\n",
      "Retrieved result would be : 5 ---------------->\n",
      "Here are four common sense steps as we move forward safely.\n",
      "--------------------------------------------- >\n",
      "Retrieved result would be : 6 ---------------->\n",
      "Third – we can end the shutdown of schools and businesses. We have the tools we need.\n",
      "--------------------------------------------- >\n"
     ]
    }
   ],
   "source": [
    "for i , docs in enumerate(multiquery_results):\n",
    "    print(f\"Retrieved result would be : {i+1} ---------------->\")\n",
    "    print(docs.page_content)\n",
    "    print(\"-\"*45,\">\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31aa55a-2c59-410c-a9d2-083a0b9c3717",
   "metadata": {},
   "source": [
    "# SINGLE QUERY RETRIEVER USING PDF DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a584ac6c-91ab-4b39-b69a-e023f2e62a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/ioch1wsxkfqgfLLgmd-6Rw/langchain-paper.pdf\"\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "pdf_loader = PyPDFLoader(url)\n",
    "\n",
    "pdf_data = pdf_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9fbdccc3-699c-4d5e-ae3d-5b87dfe8d5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_chunks = splitter.split_documents(pdf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b9e1501e-e4da-4d21-b365-7083c937850e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/ioch1wsxkfqgfLLgmd-6Rw/langchain-paper.pdf', 'page': 0}, page_content='* corresponding author - jkim72@kent.edu \\nRevolutionizing Mental Health Care through \\nLangChain: A Journey with a Large Language \\nModel\\nAditi Singh \\n Computer Science  \\n Cleveland State University')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6b10ed0b-d4b3-44ed-b107-82fcb5952404",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_embeddings = embedding_model.embed_documents(pdf_chunks[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "805fc534-34bf-40cd-8892-0d2f4e45d79a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pdf_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "03f03f96-c7bc-42bb-930f-0d910d8d9a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "for i in range(len(pdf_chunks)):\n",
    "    index.append(str(i))\n",
    "len(index)\n",
    "idx = []\n",
    "for i in range(len(pdf_chunks)):\n",
    "    idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5d7ee2f5-25db-4bc5-b5ee-4ff6d36f4190",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_chroma_db = Chroma.from_documents(pdf_chunks, embedding_model, ids = index)\n",
    "pdf_faiss_db = FAISS.from_documents(pdf_chunks, embedding_model , ids = idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "78b6f766-7dba-4810-9610-209a0aa33eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf_chunks used for Single Query Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c5152c0c-fe82-458c-92fa-f17d0bd786dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(pdf_chunks):\n",
    "    doc.metadata[\"source\"] = f\"page_{i+1}.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "747e55fc-01d9-4344-b50a-5e0c6b016fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from lark import lark\n",
    "import json\n",
    "\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"from where data has been fetched\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name = 'page',\n",
    "        description = \"On which page this data is written in the pdf\",\n",
    "        type = 'integer'\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "651f9dc3-e0cd-450e-96ce-7d0ca2e2ca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_content_description = \"Give me the brief introduction of Langchain ?\"\n",
    "\n",
    "self_query_retriever = SelfQueryRetriever.from_llm(\n",
    "    llm, \n",
    "    pdf_chroma_db,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b0894d0c-06b7-41b3-b95e-0808686f8ab0",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutputParserException",
     "evalue": "Parsing text\nHere are the structured requests for each example:\n\n### Example 1\nData Source:\n```json\n{\n    \"content\": \"Lyrics of a song\",\n    \"attributes\": {\n        \"artist\": {\n            \"type\": \"string\",\n            \"description\": \"Name of the song artist\"\n        },\n        \"length\": {\n            \"type\": \"integer\",\n            \"description\": \"Length of the song in seconds\"\n        },\n        \"genre\": {\n            \"type\": \"string\",\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\n        }\n    }\n}\n```\n\nUser Query:\nWhat are songs by Taylor Swift or Katy Perry about teenage romance under 3 minutes long in the dance pop genre\n\nStructured Request:\n```json\n{\n    \"query\": \"teenager love\",\n    \"filter\": \"and(or(eq(\\\"artist\\\", \\\"Taylor Swift\\\"), eq(\\\"artist\\\", \\\"Katy Perry\\\")), lt(\\\"length\\\", 180), eq(\\\"genre\\\", \\\"pop\\\"))\"\n}\n```\n\n### Example 2\nData Source:\n```json\n{\n    \"content\": \"Lyrics of a song\",\n    \"attributes\": {\n        \"artist\": {\n            \"type\": \"string\",\n            \"description\": \"Name of the song artist\"\n        },\n        \"length\": {\n            \"type\": \"integer\",\n            \"description\": \"Length of the song in seconds\"\n        },\n        \"genre\": {\n            \"type\": \"string\",\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\n        }\n    }\n}\n```\n\nUser Query:\nWhat are songs that were not published on Spotify\n\nStructured Request:\n```json\n{\n    \"query\": \"\",\n    \"filter\": \"NO_FILTER\"\n}\n```\n\n### Example 3\nData Source:\n```json\n{\n    \"content\": \"Give me the brief introduction of Langchain ?\",\n    \"attributes\": {\n        \"source\": {\n            \"description\": \"from where data has been fetched\",\n            \"type\": \"string\"\n        },\n        \"page\": {\n            \"description\": \"On which page this data is written in the pdf\",\n            \"type\": \"integer\"\n        }\n    }\n}\n```\n\nUser Query:\ni want to know langchain implementation\n\nStructured Request:\n```json\n{\n    \"query\": \"langchain impl\",\n    \"filter\": \"\"\n}\n```\n raised following error:\nGot invalid JSON object. Error: Expecting ',' delimiter: line 14 column 53 (char 393)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\utils\\json.py:183\u001b[0m, in \u001b[0;36mparse_and_check_json_markdown\u001b[1;34m(text, expected_keys)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 183\u001b[0m     json_obj \u001b[38;5;241m=\u001b[39m parse_json_markdown(text)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m json\u001b[38;5;241m.\u001b[39mJSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\utils\\json.py:147\u001b[0m, in \u001b[0;36mparse_json_markdown\u001b[1;34m(json_string, parser)\u001b[0m\n\u001b[0;32m    146\u001b[0m         json_str \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 147\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parse_json(json_str, parser\u001b[38;5;241m=\u001b[39mparser)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\utils\\json.py:163\u001b[0m, in \u001b[0;36m_parse_json\u001b[1;34m(json_str, parser)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;66;03m# Parse the JSON string into a Python dictionary\u001b[39;00m\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m parser(json_str)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\utils\\json.py:118\u001b[0m, in \u001b[0;36mparse_partial_json\u001b[1;34m(s, strict)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# If we got here, we ran out of characters to remove\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# and still couldn't parse the string as JSON, so return the parse error\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# for the original string.\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mloads(s, strict\u001b[38;5;241m=\u001b[39mstrict)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\json\\__init__.py:359\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    358\u001b[0m     kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparse_constant\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m parse_constant\n\u001b[1;32m--> 359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39mdecode(s)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_decode(s, idx\u001b[38;5;241m=\u001b[39m_w(s, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mend())\n\u001b[0;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\json\\decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting ',' delimiter: line 14 column 53 (char 393)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain\\chains\\query_constructor\\base.py:50\u001b[0m, in \u001b[0;36mStructuredQueryOutputParser.parse\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     49\u001b[0m allowed_keys \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilter\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlimit\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 50\u001b[0m parsed \u001b[38;5;241m=\u001b[39m parse_and_check_json_markdown(text, expected_keys)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parsed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parsed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\utils\\json.py:185\u001b[0m, in \u001b[0;36mparse_and_check_json_markdown\u001b[1;34m(text, expected_keys)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m json\u001b[38;5;241m.\u001b[39mJSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot invalid JSON object. Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m expected_keys:\n",
      "\u001b[1;31mOutputParserException\u001b[0m: Got invalid JSON object. Error: Expecting ',' delimiter: line 14 column 53 (char 393)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[148], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m self_qeury_results \u001b[38;5;241m=\u001b[39m self_query_retriever\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi want to know langchain implementation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\retrievers.py:221\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    220\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_error(e)\n\u001b[1;32m--> 221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    223\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_end(\n\u001b[0;32m    224\u001b[0m         result,\n\u001b[0;32m    225\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\retrievers.py:214\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[1;32m--> 214\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(\n\u001b[0;32m    215\u001b[0m         \u001b[38;5;28minput\u001b[39m, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs\n\u001b[0;32m    216\u001b[0m     )\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    218\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain\\retrievers\\self_query\\base.py:263\u001b[0m, in \u001b[0;36mSelfQueryRetriever._get_relevant_documents\u001b[1;34m(self, query, run_manager)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_relevant_documents\u001b[39m(\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m, run_manager: CallbackManagerForRetrieverRun\n\u001b[0;32m    254\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m    255\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get documents relevant for a query.\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \n\u001b[0;32m    257\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;124;03m        List of relevant documents\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 263\u001b[0m     structured_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery_constructor\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m    264\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: query}, config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_manager\u001b[38;5;241m.\u001b[39mget_child()}\n\u001b[0;32m    265\u001b[0m     )\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[0;32m    267\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated Query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstructured_query\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5006\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5000\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5001\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5002\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   5003\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5004\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   5005\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5006\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m   5007\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   5008\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   5009\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   5010\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2824\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   2822\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2823\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2824\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n\u001b[0;32m   2825\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   2826\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\output_parsers\\base.py:192\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m    184\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result(\n\u001b[0;32m    185\u001b[0m             [ChatGeneration(message\u001b[38;5;241m=\u001b[39minner_input)]\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    189\u001b[0m         run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    190\u001b[0m     )\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m    193\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result([Generation(text\u001b[38;5;241m=\u001b[39minner_input)]),\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    195\u001b[0m         config,\n\u001b[0;32m    196\u001b[0m         run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    197\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1734\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   1730\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m   1731\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[0;32m   1732\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1733\u001b[0m         Output,\n\u001b[1;32m-> 1734\u001b[0m         context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m   1735\u001b[0m             call_func_with_variable_args,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1736\u001b[0m             func,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1737\u001b[0m             \u001b[38;5;28minput\u001b[39m,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m             config,\n\u001b[0;32m   1739\u001b[0m             run_manager,\n\u001b[0;32m   1740\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1741\u001b[0m         ),\n\u001b[0;32m   1742\u001b[0m     )\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1744\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\config.py:379\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    378\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\output_parsers\\base.py:193\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke.<locals>.<lambda>\u001b[1;34m(inner_input)\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m    184\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result(\n\u001b[0;32m    185\u001b[0m             [ChatGeneration(message\u001b[38;5;241m=\u001b[39minner_input)]\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    189\u001b[0m         run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    190\u001b[0m     )\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m--> 193\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result([Generation(text\u001b[38;5;241m=\u001b[39minner_input)]),\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    195\u001b[0m         config,\n\u001b[0;32m    196\u001b[0m         run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    197\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\output_parsers\\base.py:237\u001b[0m, in \u001b[0;36mBaseOutputParser.parse_result\u001b[1;34m(self, result, partial)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_result\u001b[39m(\u001b[38;5;28mself\u001b[39m, result: List[Generation], \u001b[38;5;241m*\u001b[39m, partial: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m    223\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Parse a list of candidate model Generations into a specific format.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03m    The return value is parsed from only the first Generation in the result, which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;124;03m        Structured output.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse(result[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain\\chains\\query_constructor\\base.py:63\u001b[0m, in \u001b[0;36mStructuredQueryOutputParser.parse\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m StructuredQuery(\n\u001b[0;32m     60\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m parsed\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m allowed_keys}\n\u001b[0;32m     61\u001b[0m     )\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 63\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParsing text\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m raised following error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     65\u001b[0m     )\n",
      "\u001b[1;31mOutputParserException\u001b[0m: Parsing text\nHere are the structured requests for each example:\n\n### Example 1\nData Source:\n```json\n{\n    \"content\": \"Lyrics of a song\",\n    \"attributes\": {\n        \"artist\": {\n            \"type\": \"string\",\n            \"description\": \"Name of the song artist\"\n        },\n        \"length\": {\n            \"type\": \"integer\",\n            \"description\": \"Length of the song in seconds\"\n        },\n        \"genre\": {\n            \"type\": \"string\",\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\n        }\n    }\n}\n```\n\nUser Query:\nWhat are songs by Taylor Swift or Katy Perry about teenage romance under 3 minutes long in the dance pop genre\n\nStructured Request:\n```json\n{\n    \"query\": \"teenager love\",\n    \"filter\": \"and(or(eq(\\\"artist\\\", \\\"Taylor Swift\\\"), eq(\\\"artist\\\", \\\"Katy Perry\\\")), lt(\\\"length\\\", 180), eq(\\\"genre\\\", \\\"pop\\\"))\"\n}\n```\n\n### Example 2\nData Source:\n```json\n{\n    \"content\": \"Lyrics of a song\",\n    \"attributes\": {\n        \"artist\": {\n            \"type\": \"string\",\n            \"description\": \"Name of the song artist\"\n        },\n        \"length\": {\n            \"type\": \"integer\",\n            \"description\": \"Length of the song in seconds\"\n        },\n        \"genre\": {\n            \"type\": \"string\",\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\n        }\n    }\n}\n```\n\nUser Query:\nWhat are songs that were not published on Spotify\n\nStructured Request:\n```json\n{\n    \"query\": \"\",\n    \"filter\": \"NO_FILTER\"\n}\n```\n\n### Example 3\nData Source:\n```json\n{\n    \"content\": \"Give me the brief introduction of Langchain ?\",\n    \"attributes\": {\n        \"source\": {\n            \"description\": \"from where data has been fetched\",\n            \"type\": \"string\"\n        },\n        \"page\": {\n            \"description\": \"On which page this data is written in the pdf\",\n            \"type\": \"integer\"\n        }\n    }\n}\n```\n\nUser Query:\ni want to know langchain implementation\n\nStructured Request:\n```json\n{\n    \"query\": \"langchain impl\",\n    \"filter\": \"\"\n}\n```\n raised following error:\nGot invalid JSON object. Error: Expecting ',' delimiter: line 14 column 53 (char 393)"
     ]
    }
   ],
   "source": [
    "self_qeury_results = self_query_retriever.invoke(\"i want to know langchain implementation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f61932-ac07-41c4-9b30-1881d60fd49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_qeury_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea44370-4f3e-4714-adce-1cea06efa559",
   "metadata": {},
   "source": [
    "# Parent Document Retriever "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7cb9677c-7a95-4299-9a4f-cdd120a78e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "store = InMemoryStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "091ce73f-8ba0-4e4f-979c-f64dc82c01f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size = 2000, chunk_overlap = 20)\n",
    "parent_splitter = RecursiveCharacterTextSplitter(chunk_size = 400, chunk_overlap = 30)\n",
    "\n",
    "parent_document_retriever = ParentDocumentRetriever(\n",
    "    vectorstore  = pdf_faiss_db,\n",
    "    docstore = store,\n",
    "    child_splitter = child_splitter,\n",
    "    parent_splitter = parent_splitter,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7e9725b3-b114-4dc1-837d-42602d9e78ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_document_result = parent_document_retriever.invoke(\"i want to know langchain implementation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d7f0357d-d62c-466a-8786-8eea03177b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_document_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93348f29-7c84-424b-a85a-ff2c74c38720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
