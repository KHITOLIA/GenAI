{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6515ab0-7ace-4856-aa52-e9de999b2bc3",
   "metadata": {},
   "source": [
    "# Langchain Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d1521e-7dc7-47d1-93b6-941b4e26b32b",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "946853a0-0a4a-4ab4-a23e-c7335551b871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from langchain.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d1c243a-9057-4102-aece-a52a557bbcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_ollama = ollama.Client()\n",
    "model = 'mistral'\n",
    "output = llm_ollama.generate(model = model, prompt = \"In today's sales meeting, we\").response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8929cd3-151b-4ac3-8a53-c43886721eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Discuss the performance of each sales representative and provide feedback on their strengths and areas for improvement.\n",
      "\n",
      "2. Present new product offerings or updates and explain their features, benefits, and target market.\n",
      "\n",
      "3. Share insights on current market trends and competitor activities to help sales reps better understand the industry landscape and stay competitive.\n",
      "\n",
      "4. Introduce any changes in sales strategies, tactics, or tools that will help increase productivity and efficiency.\n",
      "\n",
      "5. Set sales targets for the upcoming quarter and discuss the steps each rep can take to achieve their goals.\n",
      "\n",
      "6. Encourage collaboration among team members by sharing best practices, success stories, and brainstorming ideas on how to improve the sales process.\n",
      "\n",
      "7. Provide resources, training opportunities, or support that reps may need to excel in their roles.\n",
      "\n",
      "8. Recognize and celebrate the achievements of top-performing reps as a motivator for continued success.\n",
      "\n",
      "9. Address any challenges or obstacles that the sales team might be facing and come up with solutions to help overcome them.\n",
      "\n",
      "10. Encourage open communication, constructive feedback, and a positive work environment throughout the team.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a28677-237d-4afa-94c6-4ad1826afdd5",
   "metadata": {},
   "source": [
    "# Chat Model : Direct Chat message to LLM normal conversation but you have to use Langchain to integrate this feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb17f7ba-7d7c-417a-bc6d-9d22a5f93c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ollama_llm = Ollama(model = 'mistral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ca98f71-7848-4212-b474-67c23abe686e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Man's best friend is often referred to as a dog. This phrase comes from the deep bond and loyalty that humans share with dogs, which have been domesticated for thousands of years. However, it's important to note that friendship can take many forms, and every animal (and person) has its unique qualities to offer. The best friend could also be your cat, bird, or even an aquarium fish, depending on the bond you share!\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ollama_llm.invoke(\"Who is man's best friend?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a0db23-5b68-4453-923c-60879472ba65",
   "metadata": {},
   "source": [
    "# Chat Message : Takes a list of model as input and return a message. All have a role and content properly\n",
    "1. SystemMessage :- Used for priming ai behaviour , usually passed in as the first sequence of input message\n",
    "2. HumanMessage :- Represents a message from a person interacting with a chat model\n",
    "3. AIMessage :- Represents a message from the chat model. This can be either text or request to invoke a tool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1a19f19-3466-4b3c-937e-7dc1a1d26bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage,HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0826f1ea-17cd-4e3c-894e-03f843dc8b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " You might consider enrolling in the \"Full-Stack AI Course by edX,\" which provides comprehensive lessons on Generalized Artificial Intelligence.\n"
     ]
    }
   ],
   "source": [
    "msg = Ollama_llm.invoke([\n",
    "    SystemMessage(content = \"You are a helpful AI bot that assists a user in choosing the perfect book to read in one short sentence\"),\n",
    "    HumanMessage(content = \"I want to learn GEN AI full Stack Course from where i can find these courses?\")\n",
    "])\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e64d041c-0238-429a-a8ca-0378b66fea5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Attend a CrossFit class 3-4 times per week for optimal results, while also incorporating rest days to allow your body to recover effectively.\n"
     ]
    }
   ],
   "source": [
    "msg = Ollama_llm.invoke(\n",
    "    [\n",
    "        SystemMessage(content=\"You are a supportive AI bot that suggests fitness activities to a user in one short sentence\"),\n",
    "        HumanMessage(content=\"I like high-intensity workouts, what should I do?\"),\n",
    "        AIMessage(content=\"You should try a CrossFit class\"),\n",
    "        HumanMessage(content=\"How often should I attend?\")\n",
    "    ]\n",
    ")\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd03f381-75b9-4f19-8574-c1dbd004b2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt Template had been discussed before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6466b240-4f85-4fd2-9d00-e2ab18534669",
   "metadata": {},
   "source": [
    "# Chat Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bfc44293-26b8-4924-9f43-cc7ac443222b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assistant'), HumanMessage(content='Tell me a joke about cats')])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    (\"user\", \"Tell me a joke about {topic}\")\n",
    "]) # used for only chat messages\n",
    "input_ = {\"topic\" : \"cats\"}\n",
    "prompt.invoke(input_)\n",
    "# prompt Now this prompt can be used further for giving an input to your model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a959db38-3946-4ef7-9e48-b2bfa81bc750",
   "metadata": {},
   "source": [
    "# Messages Place Holder\n",
    "This prompt template is responsible for adding a list of messages in a particular place. In the above ChatPromptTemplate, you saw how two messages can be formatted, each one a string. But what if you want the user to pass in a list of messages that you would slot into a particular spot? This is how you use MessagesPlaceholder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b7dc2e52-ee72-470b-b768-4ed2445c6c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage  # if you want the user to pass in a list of messages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9e0f35cc-eab6-415b-8a8a-784bf209d820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='you are a helpful AI Assistant'), HumanMessage(content='Why month of june is so hot ?')])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"you are a helpful AI Assistant\"),\n",
    "    MessagesPlaceholder(\"msgs\")\n",
    "])\n",
    "\n",
    "input_ = {\"msgs\" : [HumanMessage(content = \"Why month of june is so hot ?\")]}\n",
    "prompt.invoke(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c1ac879c-3727-4c96-96e7-5b2686418bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The warmth or heat in the month of June can be attributed to several factors. Firstly, it's located within the Northern Hemisphere summer season, which generally experiences warmer temperatures due to Earth's tilt towards the sun. Secondly, geographical location plays a significant role - areas closer to the equator tend to have higher temperatures throughout the year compared to those at higher latitudes. Lastly, local weather patterns and climate conditions also influence June temperatures significantly. For instance, regions with desert climates or coastal areas may experience hotter temperatures in June due to unique regional factors such as ocean currents or dry heat.\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | Ollama_llm\n",
    "response = chain.invoke(input = input_)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81242689-93b4-43d6-a8d5-cfbf7b5fb0f2",
   "metadata": {},
   "source": [
    "# Output Parsers\n",
    "It is responsible for taking a input \n",
    "1. Json Parser\n",
    "2. CSV Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e53ec411-0100-4f82-87bf-62b65785c9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSOM PARSER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ffc467c0-5274-4c27-b354-ff3cf831b5bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': \"Why don't some animals play cards in the wild? Because there are too many cheetahs!\"}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "query = \"Tell me a joke about animals\"\n",
    "output_parser = JsonOutputParser()\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = \"Answer the user query. \\n {format_instructions} \\n {query} \\n\",\n",
    "    input_variables = [\"query\"],\n",
    "    partial_variables = {\"format_instructions\" : format_instructions}\n",
    ")\n",
    "\n",
    "chain = prompt | Ollama_llm | output_parser\n",
    "chain.invoke({\"query\" : query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1d6880d7-b400-4702-a517-d723be1a53ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8adf7da0-2d81-4146-a648-885eedfa14fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query. {format_instructions} \\n List five {subject}.\",\n",
    "    input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "\n",
    "chain = prompt | Ollama_llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2d59a1b0-2c15-45d2-8357-2e4147ceb6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. Anaconda',\n",
       " '2. Great White Shark',\n",
       " '3. Saltwater Crocodile',\n",
       " '4. Siberian Tiger',\n",
       " '5. Orca (Killer Whale)']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"subject\" : \"Who is called the Apex Predator , the myth the legend the viper?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3788d47-8884-451d-813f-1576a12b8595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
