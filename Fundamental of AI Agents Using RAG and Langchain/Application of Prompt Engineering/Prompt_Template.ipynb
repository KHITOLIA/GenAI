{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6763a60-7184-497d-a9e0-70bf7d219780",
   "metadata": {},
   "source": [
    "# Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1b7ebf21-f2e2-415d-bf7a-49f0c9ce1501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16a6e11f-a758-434c-bb0e-c4a8547784d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['adjective', 'content'], template='Tell me the {adjective} joke about {content}')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"Tell me the {adjective} joke about {content}\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt # either use this or format() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa462ab8-53a1-4faf-95b5-faada864008b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model = 'mistral')\n",
    "llm_chain = LLMChain(prompt = prompt, llm=llm)\n",
    "response = llm_chain.invoke(input = {\"adjective\":\"Funny\",\"content\" : \"Humans\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6269c44a-a287-49b5-8d80-dbbaa144e084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Why don't humans need to use turn signals when driving? Because they already give plenty of warning by screaming, swerving, and tailgating!\n",
      "\n",
      "But here's another one:\n",
      "\n",
      "Why did the human go out with a pencil? Because he was afraid of going out alone with just an eraser! (A play on words, as humans often make mistakes, but can't be erased)\n"
     ]
    }
   ],
   "source": [
    "print(response['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "69eddaea-4f22-4ed4-9d83-0e66a3f62f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter your template here :  what is the {generalization} purpose of this globalization\n"
     ]
    }
   ],
   "source": [
    "def Prompt_Template(model_name, template): \n",
    "    input_vars = re.findall(r\"{(.*?)}\", template)\n",
    "    \n",
    "    input_variable = {}\n",
    "    for i in input_vars:\n",
    "        input_variable[i] = input(f\"enter your {i}\")\n",
    "    \n",
    "    prompt = PromptTemplate.from_template(template)\n",
    "    llm = Ollama(model = model_name)\n",
    "    llm_chain = LLMChain(prompt = prompt, llm = llm, verbose = True)\n",
    "    response = llm_chain.invoke(input = input_variable)\n",
    "    return response['text']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "75cfd50e-e0fb-46b1-980d-60466fc69a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter your template here :  write a python {code} for doing youtube automations !\n",
      "enter your code code to download any youtube video locally in system\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mwrite a python code to download any youtube video locally in system for doing youtube automations !\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' To download YouTube videos locally, you can use a third-party library called `pytube`. Here is an example of how to use it:\\n\\nFirst, install the necessary package:\\n\\n```bash\\npip install pytube3\\n```\\n\\nNext, create a Python script and paste the following code into it:\\n\\n```python\\nimport sys\\nfrom pytube3 import YouTube\\n\\nif len(sys.argv) != 2:\\n    print(\"Usage: python youtube_downloader.py URL\")\\n    exit()\\n\\nurl = sys.argv[1]\\nyoutube = YouTube(url)\\n\\nstream = youtube.streams.get_highest_resolution()\\n\\nvideo_title, video_extension = youtube.title, stream.default_filename_pattern.split(\\'.\\')[-1]\\noutput_filename = f\"{video_title}.{video_extension}\"\\n\\nprint(f\"Downloading {url} as {output_filename}\")\\nstream.download(output_file=output_filename)\\n```\\n\\nSave the script and run it from the command line with the desired YouTube video URL as an argument:\\n\\n```bash\\npython youtube_downloader.py https://www.youtube.com/watch?v=dQw4w9WgXcQ\\n```\\n\\nThis will download the highest quality version of the specified YouTube video and save it locally with its title as the file name.\\n\\nPlease note that using third-party libraries like `pytube3` might violate YouTube\\'s Terms of Service, so make sure to use this for personal and educational purposes only.'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = input(\"enter your template here : \")\n",
    "Prompt_Template('mistral',template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba05423-6139-4c37-8a06-e362cdf323aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49970544-11fc-4c41-9977-603b72cc2dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab8c83f-8bd0-4350-9863-c7230eee4ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657ce92c-0790-45a3-8458-eae541f8b1a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
